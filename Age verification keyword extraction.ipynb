{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV5NhbcA_wvE"
      },
      "source": [
        "The purpose of the code cell below is to query the Tobacco Truth Industry Document repository using Solr API to retrieve document IDs based on a specified query. The retrieved document IDs are stored in a list called ids_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "umaeLmeV_qwX"
      },
      "outputs": [],
      "source": [
        "#Import the requests library.This library is used to send HTTP requests to the Solr API.\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1XTI_gbAQcG"
      },
      "source": [
        "The **query_solr_api function** takes the query string and optional parameters (format, sort_field, and cursor_mark).\n",
        "**base_api** constructs the base URL for the Solr API request.\n",
        "ids_list is an empty list to store retrieved document IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "ODUz7KotA9uW",
        "outputId": "e8949f7e-d1a1-4ac8-a464-752560017343"
      },
      "outputs": [],
      "source": [
        "ids_list = []\n",
        "\n",
        "# Define the query_solr_api function\n",
        "def query_solr_api(query, format='json', sort_field='id', cursor_mark='*'):\n",
        "    global ids_list  # Declare ids_list as global\n",
        "    base_api = f'https://solr.idl.ucsf.edu/solr/ltdl3/query?q={query}&wt={format}'\n",
        "    ids_list = []  # Initialize the global ids_list\n",
        "\n",
        "    # while loop to retrieve documents, the loop will run as long as the cursor mark is valid\n",
        "    while cursor_mark:\n",
        "        api_final = f\"{base_api}&cursorMark={cursor_mark}&sort={sort_field}%20desc\"  # constructs the final API url with the current cursor_mark and sorting. \n",
        "        try:\n",
        "            response = requests.get(api_final)\n",
        "            response.raise_for_status()\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "\n",
        "        data = response.json()\n",
        "        documents = data.get('response', {}).get('docs', [])  # extracts the list of documents from the response.\n",
        "        ids_list.extend([doc['id'] for doc in documents if 'id' in doc])  # adds the id of each document to ids_list if it exists.\n",
        "\n",
        "        # prints information about the current step\n",
        "        print(f\"Retrieved {len(documents)} documents. Total IDs collected: {len(ids_list)}\")\n",
        "\n",
        "        # retrieves the next cursor mark for next set of documents. Checks if the cursor_mark hasn't changed to avoid an infinite loop, breaking the loop if it hasn't.\n",
        "        next_cursor_mark = data.get('nextCursorMark', None)\n",
        "        if cursor_mark == next_cursor_mark:\n",
        "            break\n",
        "        cursor_mark = next_cursor_mark\n",
        "\n",
        "    # Final output information\n",
        "    print(f\"Total number of document IDs collected: {len(ids_list)}\")\n",
        "    print(f\"Last cursor mark used: {cursor_mark}\")\n",
        "\n",
        "    return ids_list\n",
        "\n",
        "# Example usage of the function\n",
        "def main():\n",
        "    query = '(collection:\"JUUL labs Collection\" AND case:\"State of North Carolina\" AND \"secret shop\" AND type:\"email\")'\n",
        "    ids_list = query_solr_api(query)\n",
        "    print(f\"Collected document IDs: {ids_list}\")\n",
        "\n",
        "# Ensures that main function is called only if the script is run directly (not imported as a module)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'(collection:\"JUUL labs Collection\" AND case:\"State of North Carolina\" AND \"secret shop\" AND: type:\"email\")'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import csv\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "ename": "OverflowError",
          "evalue": "Python int too large to convert to C long",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[33], line 23\u001b[0m\n\u001b[0;32m     18\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;129;01mand\u001b[39;00m row[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m ids_set:\n\u001b[0;32m     19\u001b[0m                             \u001b[38;5;66;03m# print(f\"Processing ID: {row[0]}\")\u001b[39;00m\n\u001b[0;32m     20\u001b[0m                             writer\u001b[38;5;241m.\u001b[39mwriterow([row[\u001b[38;5;241m0\u001b[39m], row[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m---> 23\u001b[0m extract_data_from_csvs(zip_file_path, ids_list, output_csv)\n",
            "Cell \u001b[1;32mIn[21], line 38\u001b[0m, in \u001b[0;36mextract_data_from_csvs\u001b[1;34m(zip_file_path, ids_list, output_csv)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_data_from_csvs\u001b[39m(zip_file_path, ids_list, output_csv):\n\u001b[0;32m     37\u001b[0m     ids_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(ids_list)\n\u001b[1;32m---> 38\u001b[0m     csv\u001b[38;5;241m.\u001b[39mfield_size_limit(sys\u001b[38;5;241m.\u001b[39mmaxsize)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(zip_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m z:\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_csv, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out_file:\n",
            "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
          ]
        }
      ],
      "source": [
        "zip_file_path = 'data\\JUUL_Labs_Collection.zip'\n",
        "output_csv = 'data\\ocr_texts_age_verification.csv'\n",
        "\n",
        "# Define the extract_ocr_data_from_csvs function\n",
        "def extract_ocr_data_from_csvs(zip_file_path, ids_list, output_csv):\n",
        "    ids_set = set(ids_list)\n",
        "\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
        "        with open(output_csv, 'w', newline='', encoding='utf-8') as out_file:\n",
        "            writer = csv.writer(out_file)\n",
        "            writer.writerow(['id', 'text'])\n",
        "\n",
        "            for file_name in z.namelist():\n",
        "                with z.open(file_name) as csvfile:\n",
        "                    lines = csvfile.read().decode('utf-8').splitlines()\n",
        "                    for line in lines:\n",
        "                        row = line.replace('\\0', '').split('|')\n",
        "                        if row and row[0] in ids_set:\n",
        "                            # print(f\"Processing ID: {row[0]}\")\n",
        "                            writer.writerow([row[0], row[-1]])\n",
        "\n",
        "\n",
        "extract_data_from_csvs(zip_file_path, ids_list, output_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4QdS5ogUBYLU"
      },
      "outputs": [],
      "source": [
        "def extract_emails(ocr_text):\n",
        "    # Split the text into individual emails\n",
        "    email_pattern = r'(?=From:\\s)|(?=To:\\s)|(?=Sent:\\s)|(?=Subject:\\s)'\n",
        "    emails = re.split(email_pattern, ocr_text)\n",
        "\n",
        "    # Initialize an empty list to hold individual email data\n",
        "    email_data = []\n",
        "\n",
        "    # Iterate through each split email section\n",
        "    for email in emails:\n",
        "        if not email.strip():\n",
        "            continue\n",
        "\n",
        "        # Extract the body of the email\n",
        "        body_start = email.find('\\n\\n') + 2\n",
        "        body = email[body_start:].strip() if body_start > 1 else email.strip()\n",
        "\n",
        "        # Append the extracted data to the email_data list if the body has content\n",
        "        if body:\n",
        "            email_data.append({\n",
        "                'Body': body\n",
        "            })\n",
        "    \n",
        "    return email_data\n",
        "\n",
        "def process_csv(input_csv, output_csv, num_documents=500):\n",
        "    # Read the input CSV file\n",
        "    with open(input_csv, 'r', newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        rows = list(reader)[:num_documents]  # Process only the first `num_documents` rows\n",
        "    \n",
        "    # Prepare the output CSV file\n",
        "    csv_columns = ['DocumentID', 'Body']\n",
        "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
        "        writer.writeheader()\n",
        "\n",
        "        # Process each row in the input CSV\n",
        "        for row in rows:\n",
        "            document_id = row['id']\n",
        "            ocr_text = row['text']\n",
        "            emails = extract_emails(ocr_text)\n",
        "            \n",
        "            for email in emails:\n",
        "                if email['Body'].strip():  # Check if the body has content\n",
        "                    email['DocumentID'] = document_id\n",
        "                    writer.writerow(email)\n",
        "    #print(f\"Extracted emails from first {num_documents} documents saved to {output_csv}\")\n",
        "\n",
        "# Define input and output CSV file paths\n",
        "input_csv = 'data\\ocr_texts_secret_shopper.csv'  # Input CSV file path\n",
        "output_csv = 'extracted_ocr_text.csv'  # Output CSV file path\n",
        "\n",
        "# Process the first 100 documents from the input CSV and save extracted emails to the output CSV\n",
        "process_csv(input_csv, output_csv, num_documents=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install transformers\n",
        "%pip install keras\n",
        "%pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.models.bart.modeling_tf_bart because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\rolando\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\rolando\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1535\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\rolando\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\rolando\\anaconda3\\Lib\\site-packages\\transformers\\models\\bart\\modeling_tf_bart.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     TFBaseModelOutput,\n\u001b[0;32m     29\u001b[0m     TFBaseModelOutputWithPastAndCrossAttentions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     TFSeq2SeqSequenceClassifierOutput,\n\u001b[0;32m     33\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\rolando\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
            "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(input_csv)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Use the transformer3/H2-keywordextractor to extract keywords\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarization\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformer3/H2-keywordextractor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_keywords\u001b[39m(text):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Using the summarization pipeline to extract keywords\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     keywords \u001b[38;5;241m=\u001b[39m pipe(text, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\rolando\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:906\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 906\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    907\u001b[0m         model,\n\u001b[0;32m    908\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    909\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    910\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    911\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    914\u001b[0m     )\n\u001b[0;32m    916\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    917\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
            "File \u001b[1;32mc:\\Users\\rolando\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:258\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m         classes\u001b[38;5;241m.\u001b[39mappend(_class)\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m look_tf:\n\u001b[1;32m--> 258\u001b[0m     _class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(transformers_module, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchitecture\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    260\u001b[0m         classes\u001b[38;5;241m.\u001b[39mappend(_class)\n",
            "File \u001b[1;32mc:\\Users\\rolando\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1526\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1525\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1526\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1527\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1528\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\rolando\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1525\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1523\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1525\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1526\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1527\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\rolando\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1537\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1540\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.bart.modeling_tf_bart because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
          ]
        }
      ],
      "source": [
        "# Read the CSV file\n",
        "input_csv = 'extracted_ocr_text.csv'\n",
        "df = pd.read_csv(input_csv)\n",
        "\n",
        "# Use the transformer3/H2-keywordextractor to extract keywords\n",
        "pipe = pipeline(\"summarization\", model=\"transformer3/H2-keywordextractor\")\n",
        "\n",
        "def extract_keywords(text):\n",
        "    # Using the summarization pipeline to extract keywords\n",
        "    keywords = pipe(text, max_length=512, truncation=True)[0]['summary_text']\n",
        "    return keywords\n",
        "\n",
        "df['Keywords'] = df['Body'].apply(extract_keywords)\n",
        "\n",
        "# Store the keywords and DocumentID in a new CSV file\n",
        "output_csv = 'secret_shopper_keywords.csv'\n",
        "df[['DocumentID', 'Keywords']].to_csv(output_csv, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
