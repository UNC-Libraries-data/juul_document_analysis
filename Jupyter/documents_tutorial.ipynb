{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Instagram Threads from UCSF Industry Documents\n",
    "\n",
    "This notebook extracts and processes Instagram messages from a Parquet file, using an Instagram chat conversation as an example. The process includes:\n",
    "\n",
    "1. Load the Parquet file containing multiple document records.\n",
    "\n",
    "2. Filter the dataset by a specific document type and ID (ffcn0321), referencing the UCSF Industry Documents Library.\n",
    "\n",
    "3. Extract and structure the document's content into a table format with fields:\n",
    "    \n",
    "    - bates (unique document identifier)\n",
    "    \n",
    "    - date sent (document date sent)\n",
    "    \n",
    "    - time sent (timestamp, if available)\n",
    "    \n",
    "    - author (sender)\n",
    "    \n",
    "    - recipient (intended receiver(s))\n",
    "    \n",
    "    - message (document content or main text)\n",
    "\n",
    "4. Print the extracted Instagram thread as a Polars DataFrame for structured representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Necessary Libraries. We utilized Polars for efficient data handling and displays the extracted content in a structured table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load documents parquet file and display sample data.\n",
    "\n",
    "Here, we load the Parquet file `juul_nc_documents.parquet` into a Polars DataFrame. The code will display a preview of the dataset (first few rows) to inspect its structure. This is useful for verifying available columns before filtering or processing.\n",
    "\n",
    "The metadata is all the data we have, so let's cut down the columns and view just what we want to see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data from Parquet:\n",
      "shape: (5, 71)\n",
      "┌──────────┬─────┬─────────────┬──────────┬───┬──────────────┬──────────┬───────────┬──────────────┐\n",
      "│ id       ┆ tid ┆ bates       ┆ type     ┆ … ┆ timereceived ┆ timesent ┆ redaction ┆ ocr_text     │\n",
      "│ ---      ┆ --- ┆ ---         ┆ ---      ┆   ┆ ---          ┆ ---      ┆ ---       ┆ ---          │\n",
      "│ str      ┆ str ┆ str         ┆ str      ┆   ┆ str          ┆ str      ┆ str       ┆ str          │\n",
      "╞══════════╪═════╪═════════════╪══════════╪═══╪══════════════╪══════════╪═══════════╪══════════════╡\n",
      "│ phjp0299 ┆     ┆ JLI05520907 ┆ document ┆ … ┆              ┆          ┆           ┆ SOPHIA PERRY │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ -JOHNSON     │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ UCSF Red…    │\n",
      "│ xtly0299 ┆     ┆ JLI04260046 ┆ document ┆ … ┆              ┆          ┆           ┆ .01110iillgi │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ i.10.111110i │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ i.10.1…      │\n",
      "│ nhkw0321 ┆     ┆ JLI40929215 ┆ document ┆ … ┆              ┆          ┆           ┆ Sterne       │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ Kessler      │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ MONICA RIVA  │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ …            │\n",
      "│ phkw0321 ┆     ┆ JLI40929223 ┆ document ┆ … ┆              ┆          ┆           ┆ Sterne       │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ Kessler      │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ STERNE       │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ KESSLE…      │\n",
      "│ qhkw0321 ┆     ┆ JLI40929274 ┆ document ┆ … ┆              ┆          ┆           ┆ Kessler      │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ Sterne       │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ STERNE       │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ KESSLE…      │\n",
      "└──────────┴─────┴─────────────┴──────────┴───┴──────────────┴──────────┴───────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# load documents parquet file\n",
    "input_parquet_filename = \"juul_nc_documents.parquet\"\n",
    "df = pl.read_parquet(input_parquet_filename)\n",
    "\n",
    "# show dataframe\n",
    "print(\"Sample Data from Parquet:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6355 Instagram thread(s).\n",
      "\n",
      "shape: (5, 71)\n",
      "┌──────────┬─────┬─────────────┬──────────┬───┬──────────────┬──────────┬───────────┬──────────────┐\n",
      "│ id       ┆ tid ┆ bates       ┆ type     ┆ … ┆ timereceived ┆ timesent ┆ redaction ┆ ocr_text     │\n",
      "│ ---      ┆ --- ┆ ---         ┆ ---      ┆   ┆ ---          ┆ ---      ┆ ---       ┆ ---          │\n",
      "│ str      ┆ str ┆ str         ┆ str      ┆   ┆ str          ┆ str      ┆ str       ┆ str          │\n",
      "╞══════════╪═════╪═════════════╪══════════╪═══╪══════════════╪══════════╪═══════════╪══════════════╡\n",
      "│ qhnj0338 ┆     ┆ JLI42801990 ┆ document ┆ … ┆              ┆          ┆           ┆ CLOUD        │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ INSTAGRAM…   │\n",
      "│ ltgm0321 ┆     ┆ JLI42801257 ┆ document ┆ … ┆              ┆          ┆           ┆ CLOUD        │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ INSTAGRAM    │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ DIRECT       │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ MESSAGE…     │\n",
      "│ mtgm0321 ┆     ┆ JLI42801258 ┆ document ┆ … ┆              ┆          ┆           ┆ CLOUD        │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ INSTAGRAM    │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ DIRECT       │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ MESSAGE…     │\n",
      "│ ntgm0321 ┆     ┆ JLI42801259 ┆ document ┆ … ┆              ┆          ┆           ┆ CLOUD        │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ INSTAGRAM    │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ DIRECT       │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ MESSAGE…     │\n",
      "│ ptgm0321 ┆     ┆ JLI42801262 ┆ document ┆ … ┆              ┆          ┆           ┆ CLOUD        │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ INSTAGRAM    │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ DIRECT       │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ MESSAGE…     │\n",
      "└──────────┴─────┴─────────────┴──────────┴───┴──────────────┴──────────┴───────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# filter dataframe for only instagram threads \n",
    "instagram_docs = df.filter(pl.col(\"ocr_text\").str.to_lowercase().str.contains(\"cloud instagram direct message\"))\n",
    "print(f\"Found {instagram_docs.shape[0]} Instagram thread(s).\\n\")\n",
    "print(instagram_docs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 71)\n",
      "┌──────────┬─────┬─────────────┬──────────┬───┬──────────────┬──────────┬───────────┬──────────────┐\n",
      "│ id       ┆ tid ┆ bates       ┆ type     ┆ … ┆ timereceived ┆ timesent ┆ redaction ┆ ocr_text     │\n",
      "│ ---      ┆ --- ┆ ---         ┆ ---      ┆   ┆ ---          ┆ ---      ┆ ---       ┆ ---          │\n",
      "│ str      ┆ str ┆ str         ┆ str      ┆   ┆ str          ┆ str      ┆ str       ┆ str          │\n",
      "╞══════════╪═════╪═════════════╪══════════╪═══╪══════════════╪══════════╪═══════════╪══════════════╡\n",
      "│ qhnj0338 ┆     ┆ JLI42801990 ┆ document ┆ … ┆              ┆          ┆           ┆ CLOUD        │\n",
      "│          ┆     ┆             ┆          ┆   ┆              ┆          ┆           ┆ INSTAGRAM…   │\n",
      "└──────────┴─────┴─────────────┴──────────┴───┴──────────────┴──────────┴───────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# document id\n",
    "document_id = \"qhnj0338\"\n",
    "\n",
    "# filter for just this document\n",
    "filtered_doc = instagram_docs.filter(instagram_docs[\"id\"] == document_id)\n",
    "print(filtered_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(text):\n",
    "    messages = []\n",
    "    convo_data = {}\n",
    "    convo_data[\"num_participants\"] = re.search(r\"(?<=Display names  )\\d{1,2}\", text).group(0)\n",
    "    convo_data[\"start_date\"] = re.search(r\"(?<=First message sent date/ me  )\\d{1,2}\\/\\d{1,2}\\/\\d{4}\", text).group(0)\n",
    "    convo_data[\"start_time\"] = re.search(r\"(First message sent date/ me  \\d{1,2}\\/\\d{1,2}\\/\\d{4} )(\\d{1,2}\\:\\d{1,2}\\:\\d{1,2} \\w{2})\", text).group(2)\n",
    "    convo_data[\"end_date\"] = re.search(r\"(?<=Last message sent date/ me  )\\d{1,2}\\/\\d{1,2}\\/\\d{4}\", text).group(0)\n",
    "    convo_data[\"end_time\"] = re.search(r\"(Last message sent date/ me  \\d{1,2}\\/\\d{1,2}\\/\\d{4} )(\\d{1,2}\\:\\d{1,2}\\:\\d{1,2} \\w{2})\", text).group(2)\n",
    "    \n",
    "    convo_text = re.search(r\"(\\w+ \\w+ Time)(.+)\", text).group(2)\n",
    "    split_text = convo_text.split(\"  \")\n",
    "    cleaned_text = [x for x in split_text if (x not in [\"\", \"CONFIDENTIAL\", \"NC-JLI-Consent Judgment\"]) and (\"JLI\" not in x)]\n",
    "    i = 0\n",
    "    message_data = convo_data.copy()\n",
    "    for idx, line in enumerate(cleaned_text):\n",
    "        if i == 0:\n",
    "            message_data[\"user\"] = line\n",
    "            i=i+1\n",
    "        elif i ==1:\n",
    "            message_data[\"date_time\"] = line \n",
    "            i=i+1\n",
    "        elif i==2:\n",
    "            message_data[\"text\"] = line\n",
    "            messages.append(message_data)\n",
    "            message_data = convo_data.copy()\n",
    "            i = 0\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_example = filtered_doc[\"ocr_text\"].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLOUD INSTAGRAM DIRECT MESSAGES  CHAT PARTICIPANTS  Numberof par cipants 2  Display names juulvapor  rcorrato  Local user juulvapor  CONVERSATION DETAILS  Numberof messages 12  First message sent date/ me 9/13/2017 12:07:47 AM  Last message sent date/ me 10/7/2017 3:10:56 AM  Case me zone (UTC) Coordinated Universal Time  rcorrato  9/13/2017 12:07:47 AM  r  Are you guys going to make non nic pods  rcorrato  9/18/2017 4:46:09 PM r  Thanks!  CONFIDENTIAL JLI42801990  rcorrato 9/18/2017 7:13:31 PM  CONFIDENTIAL JLI42801991  rcorrato  9/18/2017 11:04:28 PM I/  Free pods since I'm bangin'?  rcorrato  9/19/2017 8:26:01 PM I/  Aw w  rcorrato  9/19/2017 8:28:55 PM r  Do you like menes  rcorrato  9/19/2017 8:28:58 PM I/  Memes*  rcorrato  9/23/2017 12:19:56 AM r  CONFIDENTIAL JLI42801992  CONFIDENTIAL JLI42801993  Redacted  CONFIDENTIAL JLI42801994  rcorrato 10/7/2017 3:10:56 AM  CONFIDENTIAL JLI42801995  Redacted  CONFIDENTIAL JLI42801996\n"
     ]
    }
   ],
   "source": [
    "parsed_text = re.sub(r\"\\s{2,}\", \"  \", text_example.strip())\n",
    "print(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[205], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mextract_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[201], line 4\u001b[0m, in \u001b[0;36mextract_data\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m messages \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m convo_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 4\u001b[0m convo_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_participants\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m(?<=Display names  )\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m1,2}\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m convo_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(?<=First message sent date/ me  )\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,2}\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,2}\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{4}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, text)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m convo_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(First message sent date/ me  \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,2}\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,2}\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{4}\u001b[39;00m\u001b[38;5;124m )(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,2}\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,2}\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,2} \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "extract_data(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Instagram thread with ID 'ptgm0321'\n",
      "\n",
      "shape: (3, 8)\n",
      "┌────────────┬────────────┬────────────┬───────────┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ num_partic ┆ start_date ┆ start_time ┆ end_date  ┆ end_time  ┆ user      ┆ date_time ┆ text      │\n",
      "│ ipants     ┆ ---        ┆ ---        ┆ ---       ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│ ---        ┆ str        ┆ str        ┆ str       ┆ str       ┆ str       ┆ str       ┆ str       │\n",
      "│ str        ┆            ┆            ┆           ┆           ┆           ┆           ┆           │\n",
      "╞════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 2          ┆ 5/29/2016  ┆ 7:17:06 AM ┆ 10/1/2016 ┆ 12:01:10  ┆ jonahrath ┆ 5/29/2016 ┆ Hi there. │\n",
      "│            ┆            ┆            ┆           ┆ AM        ┆ mer       ┆ 7:17:06   ┆ Are you   │\n",
      "│            ┆            ┆            ┆           ┆           ┆           ┆ AM        ┆ sending   │\n",
      "│            ┆            ┆            ┆           ┆           ┆           ┆           ┆ out …     │\n",
      "│ 2          ┆ 5/29/2016  ┆ 7:17:06 AM ┆ 10/1/2016 ┆ 12:01:10  ┆ for you   ┆ review.   ┆ Thanks in │\n",
      "│            ┆            ┆            ┆           ┆ AM        ┆ guys on   ┆ If you    ┆ advance   │\n",
      "│            ┆            ┆            ┆           ┆           ┆ this      ┆ guys are  ┆ and have  │\n",
      "│            ┆            ┆            ┆           ┆           ┆ account   ┆ intere…   ┆ a g…      │\n",
      "│            ┆            ┆            ┆           ┆           ┆ a…        ┆           ┆           │\n",
      "│ 2          ┆ 5/29/2016  ┆ 7:17:06 AM ┆ 10/1/2016 ┆ 12:01:10  ┆ juulvapor ┆ 10/1/2016 ┆ Email us  │\n",
      "│            ┆            ┆            ┆           ┆ AM        ┆           ┆ 12:01:10  ┆ at info©j │\n",
      "│            ┆            ┆            ┆           ┆           ┆           ┆ AM        ┆ uulvaponc │\n",
      "│            ┆            ┆            ┆           ┆           ┆           ┆           ┆ om        │\n",
      "└────────────┴────────────┴────────────┴───────────┴───────────┴───────────┴───────────┴───────────┘\n",
      "\n",
      "Saved to instagram_thread_ptgm0321.csv\n"
     ]
    }
   ],
   "source": [
    "if filtered_doc.shape[0] > 0:\n",
    "    print(f\"Found Instagram thread with ID '{document_id}'\\n\")\n",
    "    text_example = filtered_doc[\"ocr_text\"].to_list()[0]\n",
    "    parsed_text = re.sub(r\"\\s{2,}\", \"  \", text_example.strip())\n",
    "\n",
    "    messages = extract_data(parsed_text)\n",
    "    chat_df = pl.DataFrame(messages)\n",
    "\n",
    "    print(chat_df)\n",
    "\n",
    "    #save to csv\n",
    "    chat_df.write_csv(f\"instagram_thread_{document_id}.csv\")\n",
    "    print(f\"\\nSaved to instagram_thread_{document_id}.csv\")\n",
    "\n",
    "else:\n",
    "    print(\"No matching Instagram document found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
